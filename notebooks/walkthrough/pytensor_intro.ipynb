{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "578f9d15-3df9-461f-befc-ab77c381a96d",
   "metadata": {},
   "source": [
    "## What is PyTensor?\n",
    "\n",
    "A library to define, manipulate, and compile computational graphs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf5f119-c085-48a1-b6b0-733ed4921303",
   "metadata": {},
   "source": [
    "### Let's break it apart\n",
    "A library to (1.) define, (2.) manipulate, and (3.) compile (0.) computational graphs.\n",
    "\n",
    "\n",
    "#### (0.) Computational graph\n",
    "\n",
    "Any program implies a computational graph [citation needed]. In PyTensor we're mostly focusing on static array-based (i.e, numpy) programs with some branching and looping primitives. Having said that, PyTensor can be easily extended to represent arbitrary types and operations although its usefulness quickly vanishes as you venture out of its area of focus.\n",
    "\n",
    "#### (1.) Definition \n",
    "In PyTensor, you define a computational graph explicitly, starting with placeholder input variables and/or constants as the inputs and composing operators that create intermediate placeholder output variables that can be used as inputs to further operators. It's made to look almost like numpy code (to reduce learning barrier and avoid too many design decisions), but it's not!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed6d4a86d7398eca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.69314718, 1.31326169])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pytensor\n",
    "import pytensor.tensor as pt\n",
    "\n",
    "# Numpy\n",
    "x = np.array([0, 1, np.e])\n",
    "y = np.log(1 + x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad2bb2e8de14febf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytensor\n",
    "x = pt.tensor(shape=(3,), dtype=\"float64\")  # placeholder\n",
    "y = pt.log(1 + x)  # placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6f5731649ea29c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log [id A]\n",
      " └─ Add [id B]\n",
      "    ├─ ExpandDims{axis=0} [id C]\n",
      "    │  └─ 1 [id D]\n",
      "    └─ <Vector(float64, shape=(3,))> [id E]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ipykernel.iostream.OutStream at 0x7fb3e19a3310>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.dprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5017f99f95ca1c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Log.0, pytensor.tensor.variable.TensorVariable)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y, type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b30a6a9db68307dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorType(float64, shape=(3,)), pytensor.tensor.type.TensorType)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.type, type(y.type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c0a5be5591f936",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Log(Add.0), pytensor.graph.basic.Apply)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.owner, type(y.owner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc75e500fb9ece2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Elemwise(scalar_op=log,inplace_pattern=<frozendict {}>),\n",
       " pytensor.tensor.elemwise.Elemwise)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.owner.op, type(y.owner.op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1bb3439391f2509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([Log.0], True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.owner.outputs, y.owner.outputs == [y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6f97556431c818f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Add.0]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.owner.inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "316c181a13627039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Add [id A]\n",
      " ├─ ExpandDims{axis=0} [id B]\n",
      " │  └─ 1 [id C]\n",
      " └─ <Vector(float64, shape=(3,))> [id D]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ipykernel.iostream.OutStream at 0x7fb3e19a3310>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.owner.inputs[0].dprint()  # And the story begins again"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8bf95ff2-1c44-4c98-9dbc-de76b94c57d2",
   "metadata": {},
   "source": [
    "For those curious: This kind of graph is a bi-partite, directed, acyclic graph composed of interconnected Variable -> Apply -> Variable nodes.\n",
    "\n",
    "Apply nodes connect input variables to output variables, via a specific operator. Variables have a type and can have an owner (the Apply node that creates them) or not (if they are root placeholder variables).\n",
    "\n",
    "Schematically: \n",
    "\n",
    "![](https://pytensor.readthedocs.io/en/latest/_images/apply.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a916500-4dfe-4ef0-90ac-84f5de9f7ce2",
   "metadata": {},
   "source": [
    "### (2) Manipulation\n",
    "\n",
    "PyTensor puts a strong focus on manipulating (and hacking) the computational graph at the Python level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f5c0907-f4f2-4c4f-8a6d-1168792b4861",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytensor.graph import rewrite_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a06f0f99-bf76-456b-b956-994db91f678b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log [id A]\n",
      " └─ Add [id B]\n",
      "    ├─ ExpandDims{axis=0} [id C]\n",
      "    │  └─ 1 [id D]\n",
      "    └─ <Vector(float64, shape=(3,))> [id E]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ipykernel.iostream.OutStream at 0x7fb3e19a3310>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.dprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bcb8e6-8866-4082-bc26-ea837200ff30",
   "metadata": {},
   "source": [
    "#### Rewrites\n",
    "\n",
    "You can rewrite graphs with different goals in mind, such as making it numerically more stable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58706c49-350a-41bb-a578-f9ce68867322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log1p [id A]\n",
      " └─ <Vector(float64, shape=(3,))> [id B]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ipykernel.iostream.OutStream at 0x7fb3e19a3310>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stable_y = rewrite_graph(y, include=(\"stabilize\",))\n",
    "stable_y.dprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80719ee3-d781-4cbc-95e3-24bc4a1cf634",
   "metadata": {},
   "source": [
    "#### Differentiation\n",
    "\n",
    "You can differentiatie it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e2fbbf1-c9da-4b72-92cd-033813ee6879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True_div [id A]\n",
      " ├─ Second [id B]\n",
      " │  ├─ Log1p [id C]\n",
      " │  │  └─ <Vector(float64, shape=(3,))> [id D]\n",
      " │  └─ ExpandDims{axis=0} [id E]\n",
      " │     └─ Second [id F]\n",
      " │        ├─ Sum{axes=None} [id G]\n",
      " │        │  └─ Log1p [id C]\n",
      " │        │     └─ ···\n",
      " │        └─ 1.0 [id H]\n",
      " └─ Add [id I]\n",
      "    ├─ ExpandDims{axis=0} [id J]\n",
      "    │  └─ 1 [id K]\n",
      "    └─ <Vector(float64, shape=(3,))> [id D]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ipykernel.iostream.OutStream at 0x7fb3e19a3310>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytensor.gradient import grad\n",
    "grad_y = grad(stable_y.sum(), wrt=x)\n",
    "grad_y.dprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11af3e0-e78b-42ee-8242-1d82e09f0812",
   "metadata": {},
   "source": [
    "Cryptic second means: keep the second input after broadcasting the shape with the first.\n",
    "Same as `np.broadcast_arrays(x, y)[1]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99df891-d478-4ec1-a5a3-fffc9bd97941",
   "metadata": {},
   "source": [
    "You can simplify / canonicalize equivalent graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ade43296-8b1e-439a-b35e-955db3161966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True_div [id A]\n",
      " ├─ [1.] [id B]\n",
      " └─ Add [id C]\n",
      "    ├─ [1.] [id B]\n",
      "    └─ <Vector(float64, shape=(3,))> [id D]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ipykernel.iostream.OutStream at 0x7fb3e19a3310>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewrite_graph(grad_y, include=(\"canonicalize\",)).dprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8adcc3c-9f27-4c4b-b73c-07a5a5ebb41b",
   "metadata": {},
   "source": [
    "Or specialize for faster computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd7b7ac3-f130-4a2b-94af-4527da4b2d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reciprocal [id A]\n",
      " └─ Add [id B]\n",
      "    ├─ [1.] [id C]\n",
      "    └─ <Vector(float64, shape=(3,))> [id D]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ipykernel.iostream.OutStream at 0x7fb3e19a3310>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewrite_graph(grad_y, include=(\"canonicalize\", \"specialize\")).dprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464527b4-d8a3-4855-bfbb-8fcc4fe05556",
   "metadata": {},
   "source": [
    "#### Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b7bebc8f-0a2b-4464-876c-6bbae2f3e7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log [id A] <Vector(float64, shape=(3,))>\n",
      " └─ Add [id B] <Vector(float64, shape=(3,))>\n",
      "    ├─ [1] [id C] <Vector(int8, shape=(1,))>\n",
      "    └─ <Vector(float64, shape=(3,))> [id D] <Vector(float64, shape=(3,))>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ipykernel.iostream.OutStream at 0x7fb3e19a3310>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.dprint(print_type=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0737a7e7-e512-4daf-af02-4714747ae587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log [id A] <Matrix(float64, shape=(2, 3))>\n",
      " └─ Add [id B] <Matrix(float64, shape=(2, 3))>\n",
      "    ├─ ExpandDims{axis=0} [id C] <Matrix(int8, shape=(1, 1))>\n",
      "    │  └─ [1] [id D] <Vector(int8, shape=(1,))>\n",
      "    └─ new_x [id E] <Matrix(float64, shape=(2, 3))>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ipykernel.iostream.OutStream at 0x7fb3e19a3310>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytensor.graph.replace import vectorize_graph\n",
    "\n",
    "new_x = pt.matrix(\"new_x\", shape=(2, 3))\n",
    "new_y = vectorize_graph(y, replace={x: new_x})\n",
    "new_y.dprint(print_type=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f443ff7b-4227-4c7c-ba34-1caaf4ef4289",
   "metadata": {},
   "source": [
    "#### Scalarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8c9cecb-1e4b-41c2-8eb6-f6c6beed7ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subtensor{i, j} [id A] <Scalar(float64, shape=())>\n",
      " ├─ Log [id B] <Matrix(float64, shape=(2, 3))>\n",
      " │  └─ Add [id C] <Matrix(float64, shape=(2, 3))>\n",
      " │     ├─ ExpandDims{axis=0} [id D] <Matrix(int8, shape=(1, 1))>\n",
      " │     │  └─ [1] [id E] <Vector(int8, shape=(1,))>\n",
      " │     └─ new_x [id F] <Matrix(float64, shape=(2, 3))>\n",
      " ├─ 0 [id G] <int64>\n",
      " └─ 1 [id H] <int64>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ipykernel.iostream.OutStream at 0x7fb3e19a3310>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "only_one_entry_of_y = new_y[0, 1]\n",
    "only_one_entry_of_y.dprint(print_type=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c80566bf-0b17-407e-9932-7dc47839be22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log [id A] <Scalar(float64, shape=())>\n",
      " └─ Add [id B] <Scalar(float64, shape=())>\n",
      "    ├─ 1.0 [id C] <Scalar(float64, shape=())>\n",
      "    └─ Subtensor{i, j} [id D] <Scalar(float64, shape=())>\n",
      "       ├─ new_x [id E] <Matrix(float64, shape=(2, 3))>\n",
      "       ├─ 0 [id F] <int64>\n",
      "       └─ 1 [id G] <int64>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ipykernel.iostream.OutStream at 0x7fb3e19a3310>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewrite_graph(only_one_entry_of_y).dprint(print_type=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353126c9-3d83-4962-b105-f74269aa5b9e",
   "metadata": {},
   "source": [
    "#### Integration\n",
    "\n",
    "Okay it can't do everything (but maybe you can extend it to?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba8aa1b-2ec1-4aa9-83ae-247fb6b1dbb1",
   "metadata": {},
   "source": [
    "#### Graph surgery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0d5b603-4619-4906-b1e8-253f7370f8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytensor.graph.replace import graph_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6fa5bad-5813-46a9-8aa8-0c5d54e88591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log [id A]\n",
      " └─ Add [id B]\n",
      "    ├─ [1] [id C]\n",
      "    └─ <Vector(float64, shape=(3,))> [id D]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ipykernel.iostream.OutStream at 0x7fb3e19a3310>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.dprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c488c7-0760-4499-997a-7f7ef528c2ed",
   "metadata": {},
   "source": [
    "You can truncate a graph easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90f9cd63-4448-4ca4-b599-d0e93643d7ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log [id A]\n",
      " └─ x_plus_1 [id B]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ipykernel.iostream.OutStream at 0x7fb3e19a3310>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_plus_1 = pt.vector(\"x_plus_1\", shape=(3,))\n",
    "new_y = graph_replace(y, replace={y.owner.inputs[0]: x_plus_1})\n",
    "new_y.dprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7eebde-76a2-4e8e-be25-bfcee065d707",
   "metadata": {},
   "source": [
    "Or etxend it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "719f8e5b-2af0-42e9-916d-4814e3eb8234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log [id A]\n",
      " └─ Add [id B]\n",
      "    ├─ [1] [id C]\n",
      "    └─ Exp [id D]\n",
      "       └─ log_x [id E]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ipykernel.iostream.OutStream at 0x7fb3e19a3310>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_x = pt.vector(\"log_x\", shape=(3,))\n",
    "new_y = graph_replace(y, replace={x: pt.exp(log_x)})\n",
    "new_y.dprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7063854-5cd4-4c89-a806-8ab04cdcef43",
   "metadata": {},
   "source": [
    "And manipulations are composable. You can rewrite, differentiate, vectorize, ... every graph you get back: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36ec85ef-e009-4baa-b339-a483bf781c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scalar_softplus [id A]\n",
      " └─ log_x [id B]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ipykernel.iostream.OutStream at 0x7fb3e19a3310>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewrite_graph(new_y, include=(\"stabilize\",)).dprint()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63af924b-2c48-4634-8254-769ec4c39b2e",
   "metadata": {},
   "source": [
    "No idea why it's not just Softplus (PR welcome), but I promise it's a stable computational graph!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd610f2a-a933-4322-8b99-f25f9d7e992e",
   "metadata": {},
   "source": [
    "### (3) Compilation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ed3570-45f3-4df4-bbfd-4ffa0497d30e",
   "metadata": {},
   "source": [
    "All this is fun and dandy but only useful if we actually use it compute stuff! \n",
    "\n",
    "PyTensor provides a critical non-composable graph operation: `function`, which converts a pytensor graph into a callable python object that takes concrete inputs and returns concrete outputs. \n",
    "\n",
    "By default it runs an extensive database of rewrites to try and optimize the computational graph, and then compiles to C (technically a mix of C and Python if not all operations have a C implementation). See https://pytensor.readthedocs.io/en/latest/extending/pipeline.html for a bit more detail.\n",
    "\n",
    "As with anything remotely useful in Python, when it comes to work you want to [STAY OUT OF PYTHON](https://www.youtube.com/watch?v=vVUnCXKuNOg) as much as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7d74a4d9-2079-4462-81a3-a4c17a271f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cos [id A]\n",
      " └─ DropDims{axes=[0, 1]} [id B]\n",
      "    └─ Blockwise{dot, (m,k),(k,n)->(m,n)} [id C]\n",
      "       ├─ ExpandDims{axis=0} [id D]\n",
      "       │  └─ Exp [id E]\n",
      "       │     └─ Sin [id F]\n",
      "       │        └─ x [id G]\n",
      "       └─ ExpandDims{axis=1} [id H]\n",
      "          └─ Exp [id E]\n",
      "             └─ ···\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ipykernel.iostream.OutStream at 0x7fb3e19a3310>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pt.vector(\"x\", shape=(None,))\n",
    "z = pt.exp(pt.sin(x))\n",
    "out = pt.cos((z[None, :] @ z[:, None]).squeeze())\n",
    "out.dprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69a5737-9271-4d57-8e9f-df42889545fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c98b61df45d6a2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_fn = pytensor.function([x], out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5a8f3eca-51bf-4a3d-a656-85df87135c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pytensor.compile.function.types.Function"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "90f520a5-eec6-42ed-abad-26204cac5868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.24843424)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_fn(np.random.randn(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3badd33e-ddb3-4aca-a27f-49275b1b994b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(-0.99915347)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_fn(np.random.randn(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e300df411e0aff49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cos [id A] d={0: [0]} 5\n",
      " └─ DropDims{axis=0} [id B] 4\n",
      "    └─ CGemv{inplace} [id C] d={0: [0]} 3\n",
      "       ├─ AllocEmpty{dtype='float64'} [id D] 1\n",
      "       │  └─ 1 [id E]\n",
      "       ├─ 1.0 [id F]\n",
      "       ├─ ExpandDims{axis=0} [id G] 2\n",
      "       │  └─ Composite{exp(sin(i0))} [id H] 0\n",
      "       │     └─ x [id I]\n",
      "       ├─ Composite{exp(sin(i0))} [id H] 0\n",
      "       │  └─ ···\n",
      "       └─ 0.0 [id J]\n",
      "\n",
      "Inner graphs:\n",
      "\n",
      "Composite{exp(sin(i0))} [id H]\n",
      " ← exp [id K] 'o0'\n",
      "    └─ sin [id L]\n",
      "       └─ i0 [id M]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ipykernel.iostream.OutStream at 0x7fb3e19a3310>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_fn.dprint(print_destroy_map=True)  # Some memory aliasing optimizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5936a640-43ca-4a37-85e5-66feeda4558f",
   "metadata": {},
   "source": [
    "PyTensor can also delegate compilation to other libraries in town, namely Numba, JAX, and PyTorch (latter still under active development)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "719fdfbe-790d-41c5-9d4a-398697f01926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cos [id A] d={0: [0]} 5\n",
      " └─ DropDims{axes=[0, 1]} [id B] 4\n",
      "    └─ dot [id C] 3\n",
      "       ├─ ExpandDims{axis=0} [id D] 2\n",
      "       │  └─ Composite{exp(sin(i0))} [id E] 0\n",
      "       │     └─ x [id F]\n",
      "       └─ ExpandDims{axis=1} [id G] 1\n",
      "          └─ Composite{exp(sin(i0))} [id E] 0\n",
      "             └─ ···\n",
      "\n",
      "Inner graphs:\n",
      "\n",
      "Composite{exp(sin(i0))} [id E]\n",
      " ← exp [id H] 'o0'\n",
      "    └─ sin [id I]\n",
      "       └─ i0 [id J]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ipykernel.iostream.OutStream at 0x7fb3e19a3310>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_numba_fn = pytensor.function([x], out, mode=\"NUMBA\")  # Numba does it's own Blas optimizations we don't have to!\n",
    "y_numba_fn.dprint(print_destroy_map=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f9fcb852-49b3-4442-86e8-eccab65f3834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.65956483)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_numba_fn(np.random.randn(3))  # first time takes long, jit compilation actually happening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b007790d-fa14-4ac4-823e-94cf2df15e35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(0.99906762)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_numba_fn(np.random.randn(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dce865a-cdf1-4670-8564-2328f4baa6de",
   "metadata": {},
   "source": [
    "## Taking a step back\n",
    "\n",
    "### What is PyTensor again?\n",
    "\n",
    "For a more coherent introduction of PyTensor and its design principles see: https://pytensor.readthedocs.io/en/latest/introduction.\n",
    "\n",
    "### How does it compare with alternative frameworks\n",
    "\n",
    "* Graph is built explicitly with placeholder inputs (common source of confusion for users)\n",
    "* It is focused on array (tensor) operations (dense and sparse). Tries to look almost like numpy / scipy, (until the abstraction breaks).\n",
    "  * There is narrow / hidden support for other types like scalars, lists, slices, random Generators, strings, None (although easy to extend)\n",
    "* Functional design (there is no variable mutation when defining graphs)\n",
    "* Strong focus on hackability / graph manipulation\n",
    "* It's completely ours! (And nobody else uses it)\n",
    "* Evolved from:\n",
    "  1. Theano which strongly inspired Tensorflow 1.x and JAX. Many concepts stood the test of time. Others have aged and provide some drag.\n",
    "  2. Aesara, which cleaned up the codebase, added alternative backends (Numba and JAX) and proved there's some interest out there in a library like this.\n",
    "\n",
    "### Why are we using it?\n",
    "\n",
    "A mix of inertia/technical debt and Stockholm syndrome of course. \n",
    "\n",
    "More seriously, Theano strongly influenced the design (and unique strengths) of PyMC. The graph based approach turned out to be perfect for the Bayesian workflow where you can reuse the same program specification for very distinct goals: ancestral random sampling (prior predictive), tuncated ancestral random sampling (posterior predictive), probability transformation and differentiation (inference and optimization), explicit graph manipulation (causal inference), and so on...\n",
    "\n",
    "Many of the stabilization optimizations that PyTensor can do are very relevant for Bayesian inference, and it's great that users don't have to worry (as much) about it. For instance passing `logit_p=logits` or `p=pm.math.invlogit(logits)` yields exactly the same graph (and stabilization)! Yuo may have known about log1p, but did you know about log1pexp (softplus above) and log1mexp?\n",
    "\n",
    "On the other hand the laziness / abstraction level makes it easier to interoperate with other popular python libraries, like numpyro / blackjax (and more generally the  JAX ecosystem), NUMBA, and even libraries in different languages, luke nutpie and BART in RUST. All this would have been more limited if PyMC were to be built on a more eager/specialized computational framework.\n",
    "\n",
    "### What's the catch?\n",
    "\n",
    "A mix of intertia/technical debt and Stockholm syndrome, this time for real. \n",
    "\n",
    "It's only us out here, and so:\n",
    "1. It takes effoct to keep up with the times (e.g., implement an xarray-like dims-based abstraction on top of PyTensor),\n",
    "2. Fix bugs and improve user experience (eg., do you find the super long error messages that PyTensor outputs useful? Ever? If not, why don't you try and make it better ;))\n",
    "3. There are less resources and community help out there to help learning the tool. If it feels you are forced to use some obscure library it's hard not to hate it! There's a reason kidnapping someone is not on the top of seduction handbooks!\n",
    "\n",
    "We hope this workshop helps in these regards! For the project to succeed in the long-term though we will need your help with it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef908886-9610-4506-94b4-a162f2eab17b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytensor",
   "language": "python",
   "name": "pytensor"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
